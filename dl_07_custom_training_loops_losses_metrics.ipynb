{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ibrah-N/Deep-Learning-Projects-Computer-Vision/blob/main/dl_07_custom_training_loops_losses_metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-L9CtT4A1nX"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwuE1uD-96F_",
        "outputId": "17302b8d-fb2d-4609-8f32-57e94c6bff5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "C-D4SReV-M8M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.metrics import Precision, Recall, TruePositives, TrueNegatives, FalsePositives, FalseNegatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "A10FcayI-Nn5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKED9lPbBE-x"
      },
      "source": [
        "## Data Loading & Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilUGHY1QBI-_"
      },
      "outputs": [],
      "source": [
        "# download dataset\n",
        "\n",
        "\n",
        "dataset, info = tfds.load('malaria', with_info=True, as_supervised=True, split='train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwSr4kE0BI8b"
      },
      "outputs": [],
      "source": [
        "# save the dataset\n",
        "\n",
        "\n",
        "dataset.save('/content/drive/MyDrive/malaria_dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OJ1FqP8pBI5U"
      },
      "outputs": [],
      "source": [
        "# load dataset if you have saved dataset\n",
        "\n",
        "\n",
        "dataset = tf.data.Dataset.load('/content/drive/MyDrive/malaria_dataset')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.take(600)"
      ],
      "metadata": {
        "id": "vh1trkNfA3Y7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CPKOZxYcA3Dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Bns2RVZNBUpC"
      },
      "outputs": [],
      "source": [
        "# resize and rescale function\n",
        "def resize_rescale(img, label):\n",
        "  img = tf.image.resize(img, (224, 224))\n",
        "  img = img/255.0\n",
        "  return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yLmRUevUBUmq"
      },
      "outputs": [],
      "source": [
        "# Train Validation Test Split ratios\n",
        "TRAIN_RATIO  =  0.8\n",
        "VAL_RATIO    =  0.1\n",
        "TEST_RATIO   =  0.1\n",
        "\n",
        "\n",
        "# labels\n",
        "labels = [\"P\", \"U\"]\n",
        "# 1 -- > U --> Uninfacted\n",
        "# 0 -- > P --> Parsitic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EagWstW1BUjx",
        "outputId": "8a8817db-7f4c-4548-ca73-abec30347497"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_dataset length : 480\n"
          ]
        }
      ],
      "source": [
        "# train split\n",
        "train_dataset = dataset.take(int(len(dataset)*TRAIN_RATIO))\n",
        "print(f\"train_dataset length : {len(train_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imxAa2rCBUg_",
        "outputId": "197446fb-193f-46ef-9b52-1c75632544bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_dataset length : 60\n"
          ]
        }
      ],
      "source": [
        "# validation split\n",
        "val_dataset = dataset.skip(int(len(dataset)*TRAIN_RATIO))\n",
        "val_dataset = val_dataset.take(int(len(dataset)*VAL_RATIO))\n",
        "print(f\"val_dataset length : {len(val_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6ilrzJfBdlE",
        "outputId": "6a717f46-10a3-4232-e1f8-ceb219952020"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_dataset length : 60\n"
          ]
        }
      ],
      "source": [
        "# test split\n",
        "test_dataset = dataset.skip(int(len(dataset)*(TEST_RATIO + VAL_RATIO)))\n",
        "test_dataset = test_dataset.take(int(len(dataset)*TEST_RATIO))\n",
        "print(f\"test_dataset length : {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gsvXjfgBdiT",
        "outputId": "b984e39d-cc58-441c-a388-a90c0fa718ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image : (32, 224, 224, 3), label: (32,)\n"
          ]
        }
      ],
      "source": [
        "# train dataset preparation\n",
        "train_dataset = (train_dataset\n",
        "                 .map(resize_rescale)\n",
        "                 .shuffle(buffer_size= 16, reshuffle_each_iteration=True)\n",
        "                 .batch(32)\n",
        "                 .prefetch(tf.data.AUTOTUNE))\n",
        "\n",
        "\n",
        "batch_1 = train_dataset.take(1)\n",
        "for img, label in batch_1.take(3):\n",
        "  print(f\"Image : {img.shape}, label: {label.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def batching(batch_img, batch_label):\n",
        "  tf.print(batch_img.shape, batch_label.shape)\n",
        "  tf.experimental.numpy.experimental_enable_numpy_behavior()\n",
        "  return batch_img, batch_label.reshape(len(batch_label), 1)"
      ],
      "metadata": {
        "id": "pIjW3lvuDV-E"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utxeQu4eBdgE",
        "outputId": "583fd2d0-ec8b-4d7e-c45c-33723d02e01c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))\n"
          ]
        }
      ],
      "source": [
        "# validation dataset preparation\n",
        "validation_dataset = (val_dataset\n",
        "                      .map(resize_rescale)\n",
        "                      .shuffle(buffer_size= 16, reshuffle_each_iteration=True)\n",
        "                      .batch(32)\n",
        "                      .prefetch(tf.data.AUTOTUNE)\n",
        "                      )\n",
        "\n",
        "\n",
        "print(validation_dataset.element_spec)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = validation_dataset.map(batching)"
      ],
      "metadata": {
        "id": "_H5lrCdtDgKj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "pyB0UoRuBmEt"
      },
      "outputs": [],
      "source": [
        "# test dataset preparation\n",
        "test_dataset = (test_dataset\n",
        "                .map(resize_rescale)\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "mhih5fJPBmAH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on-cbRKU-OIu"
      },
      "source": [
        "## Custom Losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "9d_bQFbm-Qri"
      },
      "outputs": [],
      "source": [
        "# Custom Loss Without Parameters\n",
        "\n",
        "def custom_bce(y_true, y_pred):\n",
        "  bce = tf.keras.losses.BinaryCrossentropy()\n",
        "  return bce(y_true, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "1dhd4Wtv-NlF"
      },
      "outputs": [],
      "source": [
        "# Custom Loss With Paramets\n",
        "\n",
        "def custom_bce_params(factor):\n",
        "  def loss(y_true, y_pred):\n",
        "    bce = tf.keras.losses.BinaryCrossentropy()\n",
        "    return bce(y_true, y_pred) + factor\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "oL3aLb4P-Nix"
      },
      "outputs": [],
      "source": [
        "# Custom Loss Class\n",
        "\n",
        "class CustomBCE(tf.keras.losses.Loss):\n",
        "  def __init__(self, factor):\n",
        "    super(CustomBCE, self).__init__()\n",
        "    self.factor = factor\n",
        "\n",
        "\n",
        "  def call(self, y_true, y_pred):\n",
        "    bce = tf.keras.losses.BinaryCrossentropy()\n",
        "    return bce(y_true, y_pred) + self.factor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Esn_vF-0-eFt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyQGsrhP-dxs"
      },
      "source": [
        "## Metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "DHzqOp39-NgU"
      },
      "outputs": [],
      "source": [
        "# Custom Metric Without Parameter\n",
        "\n",
        "\n",
        "def custom_ba(y_true, y_pred):\n",
        "  return tf.keras.metrics.binary_accuracy(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "2lhQA4SB-k-o"
      },
      "outputs": [],
      "source": [
        "# Custom Metric With Parameter\n",
        "\n",
        "\n",
        "def custom_ba_params(factor):\n",
        "  def metric(y_true, y_pred):\n",
        "    return tf.keras.metrics.binary_accuracy(y_true, y_pred) + factor\n",
        "  return metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "nszFDrFD-k7J"
      },
      "outputs": [],
      "source": [
        "# Custom Metric Class\n",
        "\n",
        "class CustomMetric(tf.keras.metrics.Metric):\n",
        "  def __init__(self, name=\"custom_metric\", factor=1):\n",
        "    super(CustomMetric, self).__init__(name=\"custom_metric\")\n",
        "    self.factor = factor\n",
        "    self.count = self.add_weight(name='accuracy', initializer='zeros')\n",
        "    self.total = self.add_weight(name='accuracy', initializer='zeros')\n",
        "\n",
        "\n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "    y_pred = tf.round(y_pred)\n",
        "    correct = tf.cast(tf.equal(tf.cast(y_true, dtype=tf.float32), y_pred), dtype=tf.float32)\n",
        "    self.count.assign_add(tf.reduce_sum(correct))\n",
        "    self.total.assign_add(tf.cast(tf.size(correct), dtype=tf.float32))\n",
        "\n",
        "\n",
        "  def result(self):\n",
        "    return tf.math.divide_no_nan(self.count, self.total)\n",
        "\n",
        "\n",
        "  def reset_state(self):\n",
        "    self.count.assign(0.)\n",
        "    self.total.assign(0.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "f1n4IHmZFDS1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cEuE4RCBrFl"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "IB_OhKVRBwsI"
      },
      "outputs": [],
      "source": [
        "# rate parameters for model\n",
        "DROPOUT_RATE = 0.01\n",
        "L2_REG_RATE = 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "LvU35cQfBl92"
      },
      "outputs": [],
      "source": [
        "# model architecture\n",
        "\n",
        "temp_model = tf.keras.Sequential([\n",
        "\n",
        "      tf.keras.layers.InputLayer(input_shape=(224, 224, 3)),\n",
        "\n",
        "      tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(L2_REG_RATE)),\n",
        "      tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(L2_REG_RATE)),\n",
        "      tf.keras.layers.Dropout(DROPOUT_RATE),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "      tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(L2_REG_RATE)),\n",
        "      tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(L2_REG_RATE)),\n",
        "      tf.keras.layers.Dropout(DROPOUT_RATE),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "      tf.keras.layers.MaxPool2D(pool_size=2),\n",
        "\n",
        "      tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(L2_REG_RATE)),\n",
        "      tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(L2_REG_RATE)),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "\n",
        "      tf.keras.layers.Flatten(),\n",
        "      # tf.keras.layers.Dense(units=1000, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(L2_REG_RATE)),\n",
        "      # tf.keras.layers.Dropout(DROPOUT_RATE+0.2),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Dense(units=100, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(L2_REG_RATE)),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Dense(units=10, activation='relu'),\n",
        "      tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJTYhGrKBl7b",
        "outputId": "93f29a8b-fbef-47d4-c77c-c3fb4b7748af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 222, 222, 64)      1792      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 220, 220, 64)      36928     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 220, 220, 64)      0         \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 220, 220, 64)      256       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 218, 218, 32)      18464     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 216, 216, 32)      9248      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 216, 216, 32)      0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 216, 216, 32)      128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 108, 108, 32)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 106, 106, 16)      4624      \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 104, 104, 16)      2320      \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 104, 104, 16)      64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 173056)            0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 173056)            692224    \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               17305700  \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 100)               400       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 18073169 (68.94 MB)\n",
            "Trainable params: 17726633 (67.62 MB)\n",
            "Non-trainable params: 346536 (1.32 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# model summary\n",
        "\n",
        "temp_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "0ap82HEpFDP7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "3rucBB9wEZnn"
      },
      "outputs": [],
      "source": [
        "# compile model\n",
        "\n",
        "temp_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                   loss = custom_bce,\n",
        "                   metrics = CustomMetric())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZJ22JC1EZji",
        "outputId": "4c3d5293-9e7e-4954-f5b8-5c406a5953af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            " 8/25 [========>.....................] - ETA: 7:25 - loss: 4.4669 - custom_metric: 0.6211"
          ]
        }
      ],
      "source": [
        "temp_model.fit(train_dataset, validation_data=validation_dataset,\n",
        "               epochs=2, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNXyyCJV-ruI"
      },
      "source": [
        "## Custom Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "ZFh0cw9B-uk9"
      },
      "outputs": [],
      "source": [
        "# Training Loop Function\n",
        "# Validation Loop Function\n",
        "\n",
        "\n",
        "# Training Loop Function\n",
        "@tf.function  # to be executed in Graph Mode\n",
        "def train_loop(img_batch, label_batch):\n",
        "    with tf.GradientTape() as tape:\n",
        "      train_pred = temp_model(img_batch, training=True)\n",
        "      loss = custom_bce(label_batch, train_pred)\n",
        "    partial_derivatives = tape.gradient(loss, temp_model.trainable_weights)\n",
        "    OPTIMIZER.apply_gradients(zip(partial_derivatives, temp_model.trainable_weights))\n",
        "\n",
        "    ### Metric -- BinaryAccuracy\n",
        "    TRAIN_ACCURACY.update_state(label_batch, train_pred)\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "\n",
        "# Validation Loop Function\n",
        "@tf.function  # to be executed in Graph Mode\n",
        "def val_loop(img_batch, label_batch):\n",
        "    val_pred = temp_model(img_batch, training=False)\n",
        "    val_loss = custom_bce(label_batch, val_pred)\n",
        "\n",
        "    ### Metric -- BinaryAccuracy\n",
        "    VAL_ACCURACY.update_state(label_batch, val_pred)\n",
        "\n",
        "    return val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "JHjk4zTM-3ng"
      },
      "outputs": [],
      "source": [
        "# Complete Training Loop Function\n",
        "\n",
        "\n",
        "def train(train_dataset, validation_dataset, EPOCHS=4, OPTIMIZER=tf.keras.optimizers.Adam(learning_rate=0.001)):\n",
        "  TRAIN_ACCURACY = CustomMetric()\n",
        "  VAL_ACCURACY = CustomMetric()\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "    ## Training\n",
        "    for idx, (img_batch, label_batch) in enumerate(train_dataset):\n",
        "      loss = train_loop(img_batch, label_batch)\n",
        "      ### Prompt Results After 100 steps\n",
        "      if idx % 10 == 0:\n",
        "        print(\"Epoch:{}/{} : T-Loss: {} -- T-Accuracy: {}\".format(epoch+1, EPOCHS, loss, TRAIN_ACCURACY.result()))\n",
        "\n",
        "\n",
        "    ## Validation\n",
        "    for idx, (img_batch, label_batch) in enumerate(x):\n",
        "      val_loss = val_loop(img_batch, label_batch)\n",
        "      ### Prompt Results After 100 steps\n",
        "      if idx % 10 == 0:\n",
        "        print(\"Epoch:{}/{} : V-Loss: {} -- V-Accuracy: {}\".format(epoch+1, EPOCHS, val_loss, VAL_ACCURACY.result()))\n",
        "\n",
        "\n",
        "\n",
        "    print(f\"\\n##############################\\nEpoch:{epoch+1}/{EPOCHS} : T-Loss: {loss} -- V-Loss: {val_loss} -- T-Accuracy: {TRAIN_ACCURACY.result()} -- V-Accuracy: {VAL_ACCURACY.result()}\\n##############################\\n\")\n",
        "    VAL_ACCURACY.reset_state()\n",
        "    TRAIN_ACCURACY.reset_state()\n",
        "\n",
        "\n",
        "  print(\"\\n\\n TRAINING COMPLETED!!!!!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(train_dataset=train_dataset, validation_dataset=validation_dataset, EPOCHS=2, OPTIMIZER=tf.keras.optimizers.Adam(learning_rate=0.001))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "OIA8DPlFB_7D"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNBh5jR4vD8qQY6UhN4jiN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}